## FEP Open Challenge: Test and Validate Uni-FEP Performance

### Project Overview
**FEP Open Challenge** is a long-term initiative hosted in the Uni-FEP-Benchmarks repository. We warmly invite researchers to test the accuracy and stability of Uni-FEP in free energy calculations, especially for those who have reservations about its performance. We encourage you to use your existing data or published datasets for comparative testing, and we will provide ample free Uni-FEP credits on Hermite®️ platform to support your validation efforts. Simultaneously, as the community conducts these tests, we will gradually build a public, fair, and transparent benchmark dataset. Our goal is to accumulate over 1,000 protein target-ligand complex benchmarks by the end of 2025 and share them with the global research community, thereby advancing FEP methodologies and drug activity prediction models across the field.

### Project Background
Free Energy Perturbation (FEP) methods are pivotal for optimizing lead compounds in drug discovery. However, debates persist regarding the accuracy, stability, and reproducibility of various FEP tools. To address these concerns, we launched the Uni-FEP Open Challenge within the Uni-FEP-Benchmarks repository. Our main objectives include:
- **Addressing Accuracy Concerns**: By providing free Uni-FEP credits on Hermite®️ platform for independent testing, we aim to dispel any doubts about the stability and precision of Uni-FEP.
- **Build an Open Benchmark Datase**t: Through the accumulation of validated test cases, we intend to establish a transparent and equitable benchmark dataset.
- **Encouraging Community Feedback**: If you find that another mainstream commercial FEP tool outperforms Uni-FEP under identical conditions, please provide supporting evidence, such as published papers or software result screenshots. Upon verification, additional rewards will be granted, which may include *extra Uni-FEP credits on Hermite®️ platform* or *a $50 Amazon gift card*.

### How to Participate
#### 1. Submit Your Test Case
Please create an issue in the Uni-FEP-Benchmarks repository using the dedicated submission template. Your submission should include the following files:
- **Protein Structure File (PDB)**: The 3D structural data of the target protein.
- **Reference Ligand File (SDF)**: The ligand used to identify the binding pocket.
- **Data File (CSV, SDF)**: The data file can be in CSV format (which should include molecular SMILES along with experimental activity) or in SDF format (containing experimental data). This data will help us determine the free Uni-FEP compute quota to be provided to you.
#### 2. Review and Evaluation
Each submitted test case will undergo both automated and manual review to ensure completeness and scientific rigor. Approved cases will be granted access to an Hermite®️ account along with the corresponding free Uni-FEP credits, enabling you to proceed with your FEP calculations.
#### 3. Technical Support and Feedback
We understand that various technical challenges may arise during FEP calculations. To ensure your testing proceeds smoothly, if you encounter any issues or notice abnormal results, please report them via the issue tracker. Our team of expert application scientists will provide comprehensive technical guidance and support to help resolve any difficulties.
#### 4. Public Data and Results
All validated test cases and their corresponding Uni-FEP calculation results—as well as comparative data—will be published in the repository. This continuously updated benchmark dataset will serve as an objective and transparent platform for evaluating FEP performance, contributing significantly to the advancement of drug design technologies.
#### 5. Reward Mechanism
If you can demonstrate that another mainstream commercial FEP tool outperforms Uni-FEP under identical conditions, please submit supporting evidence such as published articles or screenshots of software results. Upon verification, additional rewards will be granted, which may include *extra Uni-FEP credits on Hermite®️ platform* or *a $50 Amazon gift card*. We also welcome any constructive suggestions regarding the reward system.

### Project Guidelines and Considerations
- **Openness and Fairness**: All test cases and calculation results will be shared openly in the Uni-FEP-Benchmarks repository, creating a robust and high-quality FEP benchmark dataset.
- **Intellectual Property Protection**: We strictly respect intellectual property rights. In future publications or technical reports utilizing data from this repository, we will appropriately acknowledge and include the contributions of all participants.
- **Low Barrier to Entry**: We welcome contributions from both academic researchers and industry professionals. However, submissions will be subject to review to maintain data quality.
- **Privacy Protection**: Please anonymize any sensitive data before submission. If necessary, contact us to discuss alternative submission methods.
- **Long-Term Initiative**: This project is intended for ongoing participation with no fixed deadline. We encourage continuous contributions to progressively enhance the dataset.
